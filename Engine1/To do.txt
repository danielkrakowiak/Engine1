27.02.2014
	- Add unit tests for mesh loading (loading meshes with several triangles and resued vertices, with and without normals, texcoords)
19.03.2014
	- when creating fipImage in Texture2D - FREE_IMAGE_TYPE is set to FIT_BITMAP by default. However, it is not always the appropriate file type for image. Ex.: 16 bit grayscale heighmaps have different file type. Maybe it should depend on special file formats defined in AssetFileFormat such as RAW_16BIT?
28.03.2014
	- Handle errors in AssetManager::loadAssetsFromDisk and AssetManager::loadAssets - threads shoould not be terminated, exceptions should not be thrown, path to assets should be removed from assets - maybe handle by not doing anything?
11.04.2014
	- Write = operator for every class with copy constructor (otherwise default copy constructor will be used)
12.04.2014
	- check if DirectX SDK can be removed and if only Windows 7 SDK is enough
	- check whether all DirectX headers point to the right SDK (by pointing the cursor over an include)\
	- add texture loading to AssetManager
	- add loading to Gpu to asset manager (read about async resource loading before - probably one loading thread is enough)
15.04.2014
	- Add test case for mesh loading where mesh has some faces with texcoord indexes or normals and some without them (should throw exception if not handled correctly) - audi.obj is an example
22.09.2014
	- should loading assets asynchronously be done statically in BasicAsset class or in a separate AssetLoader class? Loading and managing assets seem to be different tasks... 
13.10.2014
	- implement loading RiggedMesh from .obj file
08.11.2014
	- add more methods for manipulation float44 and float43 - ex. getRotation rename to getRotation, get4x3 rename to getRotationTranslation, add setRotationRow1 etc
	- change bone pose format from float44 to float43 - beacuse last column is useless anyway
15.11.2014
	- methods which return references (especially to lists) should retrurn shared pointer rather than reference. 
	- add File class with path, type, data, loadedFlag? use it in all assets classes (Mesh, Texture etc)
	- SkeletonAnimation requires bonesNames to work (mapping of names to bone indexes) - how should these names be passed so that each SkeletonAnimation doesn't store a copy of that list (shared_ptr?)
	- should boneNames have it's own class with methods like getBoneIndex( std::string name ) ? - would it be used anywhere else but loading animations?
21.11.2014
	- does combining two SkeletonPoses really work? Especially in the case where the same bones are manipulated in both poses. How about joining three or more poses?
	- optimizing SkeletonPose in terms of memory usage? What is the size of this object when used for a typical or large animation?
28.12.2014
	- Const methods ( ex. const Mesh & getMesh() const ) should always return const-object or const-reference. Non-const versions of the same methods can be created to allow modification of the object. 
	- add const and non-const version of some methods (getters mostly) to all classes. Use const method in non-const method. Use const_cast<type> to convert types from const to non-const.
16.05.2014
	- Add tests for: RenderTarget2D, RenderTargetDepth2D.
21.06.2015
	- Add support for text rendering in Direct3DRendererCore. Add support for text rendering in Direct3DDeffreredRenderer (for in-game flowing label, debug texts, UI etc)
13.07.2015
	- Go through all "throw std::exception" and make sure that throwing method has parenthesis "()" in the error message.
	- Add tests for SkeletonMeshVertexShader checking if it throws for incorrect bones-per-vertex-values.
11.11.2015
	-  Texture2D::createFromMemory - WARNING: casting away const qualifier on data - need to make sure that FreeImage doesn't modify the input data!
12.11.2015
	- AssetManager: add due time as priority for each asset in AssetManager. Asset's subassets should be loaded with it's owner's priority.
	  When inserting assets to load in the queues they need to be inserted in the order of increasing due time.
	- IMPORTANT: There is one problem: if one thread (loadAssets method) waits for the sub-assets to be loaded, then it's not loading any assets at that time. Maybe there should be more threads, but only the given number of them active? Non-binary mutex or something?
29.04.2016
	- [Texture] Add constructor from exisitng DX texture and render target view (or swap chain?). For access to the backbuffer.
	- [Texture - Refactor] Can I remove initialize methods from Texture2DGeneric? Move that code to constuctors...
	- [Includes Cleanup] Some headers include <d3d11.h> although they only contain references and pointers to DX types. Replace with forward declarations.
	- [Test Texture] I should test whether constructor options like generateMipMaps (ex. for RenderTarget) really work for all the bindings and remove them if they are not supported.

For later ######################################################################################################################

//////////
 - Add some math functions to measure corruption of matrices

 - Add: matrix difference (sum of squared distances), matrix inverse, measure matrix orgonality (multiply inverse by the transpose and return difference to identity matrix)
 - Optionally add: orthogonalization - later on... To fix corrupted matrices and compare visual results

/////////

- option to read os some range of keyframes/time/ticks from animation file
- option to split an animation into a few by keyframe/time/tick etc.

- add move constructor to some classes? (but only the ones which are designed to be returned from methods by object) 
- add move assignment to some classes? (but only to those for which creating another object from an existing one makes sense)

- test combining poses (skeleton-space, parent-space)
- add method to substract poses (leave only the difference between poses)


- add option to ignore bones which are not in mesh when loading an animation file. How to make sure that missing bones are not in between of the existing ones? Useful to apply complex animation to a sipler version of mesh (LOD etc)

- Refactor Font and FontCharacter classes.

- in BlockMesh, SkeletonMesh buffer getters should return reference?

- 3d text rendering

- make RectangleMesh derive from BlockMesh (to be able to render it with BlockMeshShader) ?

Next2:

	- zdublowac gettery w SkeletonMesh tab by byly wersje const i non-const. Jak w BlockMesh.

##################################################################################################################################

--------------------------------------
	Problems with texture class:
	- No generic class without template params to be used as method arguments.
	- PixelType has no usage for textures which are only stored on gpu (like render target) - but restricts their usage in methods etc.

	How to deal with textures which are not loaded, but store file information (when parsing ModelTexture files etc). 
	Should it ba possible to create empty textures? But lock them internally to make any action impossible?
	But probably a more elegant solution can be found. 
-------------------------------------
	IMPORTANT: AssetManager tests (event the first one) make whole test execution to fail for all tests. But only in Release builds. It works fine in Debug. Why?
-------------------------------------

##################################################################################################################################

 - IMPORTANT: ray tracing shader has better performance with D3D10_SHADER_SKIP_OPTIMIZATION flag set. Why? 
   How to configure the shader to avoid optimizations only where it really improves performance, but not everywhere?
   
   Also2: pass stack depth to the shader as constant or...
   Also3: Compile a few versions of the shader with different stack depth and use the appropriate one?

   - After creating BVH for a mesh - mesh's triangle vector could be replaced with the one from BVH. It's just a matter of reordering the triangles.
     Then, there would be no need to send a seperate buffer to GPU just to mark which triangles are in BVH nodes. Nodes would already contain triangles from mesh triangle list.

	 - textures which use float4 for vectors (rayDir, rayOrigin etc) could use float3, because such format exists.

	 - add loading (drag&drop) animations and applying it to the default skeleton model if they match.
	   Would be good to check if they still work and check how reflections look for them.

	- PERFORMANCE: buffer containing "surface position" in DeferredRenderer could be reused to store ray origins in the RaytraceRenderer. 
	    It would have to be read and rewritten as UAV to slithly adjust ray origins along the surface normal to avoid self-collisions of ray with the reflective surface.

	- check how reflection looks when calculated only for even pixels. middle pixels can receive half of the calculated color from each side (addition).
	  What's the performance difference?

	- algorithm creating BVH uses the same step when moving dividing planes no matter the size of the model. 
	That's not too goood. It should use something like 1/1000 of longest bbox dimension or similar.

	- add g-buffer name display in the corner - how to do it elegantly? These are not full rgba textures...

	- final blurring of reflections: sample mipmap one/two levels less blurry than you need (with/without filtering? any cost? use filtering between points) 
	  and then apply 5x5 gaussian blurr to smoothen pixel borders. Or similar.
	  Must read before!!! : https://bartwronski.com/2014/03/23/gdc-follow-up-screenspace-reflections-filtering-and-up-sampling/

	  - should measure the cost of generating mipmaps for the color target! Compare it with cost of running blur kernels.

	  - the problem is bleeding reflections through the edges - note it down somewhere.

	  - create a edge-detection shader which writes distance to the nearest "reflection edge" based on position/normal/ray direction whatever.. Could use multiple passes and shaders.

	  - probably need to add some memory barriers in the compute shader for edge distance. Pixels written by some threads are read by others. Read aboubt sync in DX book.

	  - IMPORTANT: optimization of edge distance calculation: pass "current render pass index" to shader and then ignore threads with current edge distance smaller than pass index 
	    (they are calculated already - no point in recalculating it again). This way less and less pixels will have to be calculated each pass. And zero at some point!


	  - have to upscale mipmaps to at least half the screen size to avoid aliasing when moving camera.

	  - I could limit reflection mipmaps to let's say 4x4 - there is not much point in having even rougher reflections - and to store their upscaled mipmaps at half screen resolution.

	  - upscaling has to happen in steps - upscale by factor of 2 each render pass. Otherwise it gives no advantage over simple sampling. How to do that efficently with 3d texture?

	  - instead of texture array for reflection upscaled mipmaps use 3d texture. It allows for sampling between layers based on dynamic, float level.

	  ////////////////////

	  - why unsigned char textures are displayed/loaded with artifacts? Add texture path to debug name.

	  - IMPORTANT: FreeImage has some trouble loading grayscale png image. What's the problem?

	  - add modifying light params using keyboard shortcuts.

	  Test this idea:

	  - try decreasing far neighbors weigth and check how it influences image. It mimics how most rays reflect near center ray, so they have bigger impact.


	  * To allow for recursive ray tracing:
	  - accumulate specular term multiplier (something like combined surface param)
	  - add total distance covered by ray (maybe except for primary ray depth)
	  - accumulate roughness? accumulate based on distances between levels?

	  How to generate upscaled mipmaps:
	  - start with 2 level mipmap - render it stretched to 3d texture layer 0.
	  - take level 3 mipmap and render it to level 2 mipmap. Then render level 2 mipmap to 3d texture layer 1.
	  - take level 4 mipmap and render it to level 3 mipmap. Then render it to level 2 mipmap. Then to 3d texture layer 2.
	     and so on... - but how about the problem of binding the same resource on input and output? Should I have separate shader resource view for each mipmap level as well to avoid the problem?

   ----------------------------------------------------
   Refactoring:

	- Change naming convention: use m_ in class members.
	- use ComPtr wherever possible instead of raw pointers.
	- use short "Idx" for "index" in the whole code + shaders.
	- rename TTexture2D to Texture2D

	- add uint type, which would be just a typedef for unsigned int - could be in math in separate header file.
	- rename "ReflectedRefracted..." shader names to "SecondaryRays...".

	- shader could use g_ in global variable names. Because names often reapeat.

	- get rid of "Direct3D" from class names. It's used all over the code anyway - no reason to mark specific lass with such prefix.

	- all UAVs and render target could be uniformly called "RenderTargets" - everyone knows what that means. No need to differentiate all the time between UAV and RT.

	- should I also const things inside the vectors -> const std::vector< const std::shared_ptr< const Light > > ??

	- rendererCore should also allow for setting viewport dimensions and depth range. It's done manually in FrameRenderer and CombiningRenderer, but it's wrong this way.
   ---------------------------------------------------

*** IMPORTANT:
It's strange that we set textures in FragmentShader's setParameters method, but we set buffers in RendererCore draw method. It should be unified.
Example: draw(or renamed to render) method should take model instead of mesh and set textures accordingly. Or buffers should be set in VertexShader setParameters method...
Also constant buffer is set in setParameters...
Also only the shader know on which slots it binds resources. So only the shader know ho to bind/unbind them correctly. Doing it from outside is just guessing and won't work for more complex/diverse shaders.
So probably set buffers, textures, uavs from shader class.

**** IMPORTANT 2:
Maybe I should createa Buffer class. Same as Texture2D. Because we need to store quite many resource ptr to directx with each buffer plus C++ vector. Could be good to group them up. 
Could be a template class taking it's element type at template argument. It would also simplify sending data to and from GPU using buffers. When building volume data structures etc.
+ Check bind flags on different resources - ex. vertex buffers (and normals etc) have bind flag - "default", but should rather hvae "immutable". Default means that I expect GPU to modify these buffers.


-----------------------------------------

Ability to select an actor by clicking on it. Using ray tracing.

Add other phases of rendering. Rendering color, normals etc. Then rendering the final image. 

How to do raytracing on the GPU --------------------------

First shader: For all rays, find the intersection distance, hit actor (or model), hit triangle -> save to texture.
For each actor in the current scene node run second shader (pass model textures etc):
Second shader: For all rays, calculate the received color.

How to pass many meshes to shader at the same time?
* Maybe use one huge buffer for vertex data and each mesh has a view to only a part of this buffer.
And then also one special view to access the whole buffer.
* Or the same huge buffer approach but with each mesh remebering it's start/end index in that buffer.

----------------------------------------------------------

Implementation order:
1) Generating rays from camera (for test) or from depth buffer
2) Outputing rays as pixels, (pos, albedo, spec, roughness etc)
3) Ray-Box test
4) Shading a layer (no shadows)
5) Shadow-rays tests
6) Storing scene (mesh list/ptrs) on GPU
7) Ray-Mesh test


1) for each layer:
- render depth/pos + albedo/normal/spec/roughness (using DX or RT)
- shade - 1 pass for each light - use SM/RT -> color
2) for each layer - from the last one
- blur the reflections, refractions
- combine with the previous layer

Idea:
- when calculatin range of a light source - it's bounding volume doesn't have to be a sphere. The more precise the bounding volume to more calculations we save. Maybe even a few volumes could describe a lights range?

----------------------------

	  - should I rename refration into transmission? To differentiate them more..

	  - we probably need to store current ray refraction index - the whole history for each ray - as many buffers as there is for reflection/transmission term.
	  - if we hit surface from inside (deduced from normal), than we need to invert refraction index? How to know refractive index of air, water if we are in one mesh, inside another and another etc?

	  - rename albedo render targets to albedoAlpha.

	  - rename reflectionTerm texture in combining shader and classes. Should be called contributionTerm. Check for incorrect assumption regarding reflection/refraction too.

	  - experiment with increasing minimal contribtuion for the ray to be generated and traced. How high can we go for higher levels?

	  http://graphics.stanford.edu/courses/cs148-10-summer/docs/2006--degreve--reflection_refraction.pdf

	  - add exceptions and check if wrong level is passed to reflectionrefraction renderer.
	  - remove unnecessary 'level' and 'prev contribution term' from firstreflectionshading and firstrefractionshading.
	  
	  -----------------------------

	  - PERFORMANCE IDEA: higher level reflections/refractions could be calculated with smaller work groups - because only some pixels in the group need to be traced and many are black. Large groups cause waste of cores.

	  - MINOR: do we really care about solid object having reflections from backfacing triangles? Like inside a glass wall or aquarium wall? How could we ignore it elegantly with customization?

	  - shading is incorrect for reflection (possibly refraction too). 
	  When something has white albedo and high metalness, I should not see white albedo in reflection but only the reflected color. At least I think so...
	  Commenting out specular part in reflection shading fixes the problem. But what should I really do? Or it actually works when roughness is really low.

	  - should alpha impact the surface color used for shading? Yes. Should it also impact shading reflections?

	  - NEXT: dealing with varying refraction index.

	  - why mipmaps are not generated on gpu in TTexture? There is already a method for that in TTExtureSpecBind. Should we wait for CPU implemantation of generating mipmaps?

	  - IMPORTANT / REFACTOR: Should move all the compiled libraries and headers to one folder inside the project and add that project to repository. 

	  START HERE: !!!!!!!!!!

	  - maybe doo normalmapping in local space and then transform to world space?

	  - IMPORTANT: is normalmapping working correctly? Why tangent vector is not multiplied by world matrix in vertex shader?

	  - IMPORTANT: Can I optimize raytracing, by waiting with reading triangle normals ,texcoords etc until I decide which triangle is the closest? (instead of reading them for every temporary closest triangle).

	  - IMPORTANT: Look like normal mapping doesn't work in reflections/refractions! Or lighting is flat for some other reason. Yep, normals are flat in reflections/refractions.